{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'hash_vectorizer' from 'vectorization' (c:\\Users\\User\\Desktop\\DNA_CNT\\Code\\vectorization.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19416/246180190.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mvectorization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhash_vectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'hash_vectorizer' from 'vectorization' (c:\\Users\\User\\Desktop\\DNA_CNT\\Code\\vectorization.py)"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model as lm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from vectorization import hash_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "\n",
    "# One hot encoding ##############################\n",
    "\n",
    "def onehote(sequence):\n",
    "    mapping = {\"A\": 0, \"C\": 1, \"G\": 2, \"T\": 3}\n",
    "    seq2 = [mapping[i] for i in sequence]\n",
    "    return np.eye(4,dtype=int)[seq2]\n",
    "#One hot encoding on a list\n",
    "def seq_encoding(list):\n",
    "    return np.array([onehote(i) for i in list])\n",
    "#Dataframe column tolist().\n",
    "def toList(dataframe,column_name):\n",
    "    return dataframe[column_name].tolist()\n",
    "\n",
    "#################################################\n",
    "\n",
    "# One hot encoding on chirality #################\n",
    "\n",
    "#Get integers from chirality string\n",
    "def toInt(chirality_string):\n",
    "    buff = re.split(r\"[();]\",chirality_string)\n",
    "    return [int(buff[1]),int(buff[2])]\n",
    "\n",
    "#Get the chirality from the list of chirality strings\n",
    "def getChirality(chirality_list):\n",
    "    return np.array([toInt(i) for i in chirality_list])\n",
    "\n",
    "#Onehot encode the chirality number\n",
    "def onehot_chirality(number):\n",
    "    return np.eye(12,dtype=int)[number]\n",
    "#Onehot encode the chirality\n",
    "def extract_chirality(chirality):\n",
    "    return np.array([onehot_chirality(i) for i in chirality])\n",
    "#Apply onehot on the chirality list\n",
    "def apply_chirality(chirality_list):\n",
    "    return np.array([onehot_chirality(i) for i in chirality_list])\n",
    "\n",
    "#################################################\n",
    "\n",
    "# Misc ##########################################\n",
    "\n",
    "#Flatten the array\n",
    "def Flatten(list):\n",
    "    return np.array([list[i].flatten() for i in range(len(list))])\n",
    "\n",
    "#Make a tuple with index and value from a list\n",
    "def make_tuple(list):\n",
    "    return [(i+1,list[i]) for i in range(len(list))]\n",
    "#Make a tuple from two lists\n",
    "def make_tuple2(list1,list2):\n",
    "    if(len(list1) != len(list2)):\n",
    "        print(\"Error: Lists are not the same length\")\n",
    "        return None\n",
    "    return [(list1[i],list2[i]) for i in range(len(list1))]\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "set_raw = pd.read_csv('../Data/training_set.csv', low_memory=False)\n",
    "\n",
    "# Preprocess the data\n",
    "# Chirality\n",
    "chirality = getChirality(set_raw['Chirality'])\n",
    "chirality = pd.DataFrame(chirality, columns=['m','n'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>cc</th>\n",
       "      <th>ccc</th>\n",
       "      <th>cct</th>\n",
       "      <th>ct</th>\n",
       "      <th>ctc</th>\n",
       "      <th>ctt</th>\n",
       "      <th>t</th>\n",
       "      <th>tc</th>\n",
       "      <th>tcc</th>\n",
       "      <th>tct</th>\n",
       "      <th>tt</th>\n",
       "      <th>ttc</th>\n",
       "      <th>ttt</th>\n",
       "      <th>m</th>\n",
       "      <th>n</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     c  cc  ccc  cct  ct  ctc  ctt  t  tc  tcc  tct  tt  ttc  ttt   m  n Label\n",
       "711  6   1    0    1   4    2    2  6   4    1    2   2    2    0   8  5     N\n",
       "300  6   5    4    1   1    0    1  6   1    1    0   4    1    2  10  2     N\n",
       "46   5   0    0    0   5    3    1  7   5    0    5   1    1    0   9  7     N\n",
       "304  6   5    4    1   1    0    1  6   1    1    0   4    1    2   9  6     Y\n",
       "853  8   4    0    3   3    2    1  4   3    3    0   1    1    0  10  3     N"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform\n",
    "# Sequences\n",
    "seq = vectorization.vectorizer.transform(set_raw['Sequence'])\n",
    "seq = pd.DataFrame(seq.toarray(), columns=vectorization.vectorizer.get_feature_names_out())\n",
    "# Merge two dataframes\n",
    "set = pd.concat([seq,chirality,set_raw['Label']],axis=1)\n",
    "set.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'vectorization' has no attribute 'hash_vectorizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19416/990468913.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvectorization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhash_vectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'vectorization' has no attribute 'hash_vectorizer'"
     ]
    }
   ],
   "source": [
    "vectorization.hash_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hash Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'vectorization' has no attribute 'hash_vectorizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19416/134243164.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mseq_hash\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhash_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset_raw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sequence'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mseq_hash\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_hash\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Remove columns with all zeros\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'vectorization' has no attribute 'hash_vectorizer'"
     ]
    }
   ],
   "source": [
    "# Transform\n",
    "# Sequences\n",
    "seq_hash = vectorization.hash_vectorizer.transform(set_raw['Sequence'])\n",
    "seq_hash = pd.DataFrame(seq_hash.toarray())\n",
    "# Remove columns with all zeros\n",
    "seq_hash = seq_hash.loc[:, (seq_hash != 0).any(axis=0)]\n",
    "seq_hash.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mymodel():\n",
    "    model = lm.LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(test,\n",
    "                                                    set_raw['Label'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "#Train the model\n",
    "model = mymodel()\n",
    "model.fit(X_train, Y_train)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8fac594bfae6525c0c41b4041d2d72effa188cc8ead05f81b1fab2bb098927fb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
